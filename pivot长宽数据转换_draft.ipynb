{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d125db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据导入成功😄！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics         import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "\n",
    "path = '/data/home/zhaocj/spn_forcast/df数据整理/../7mer_output/RBIND_7mer'\n",
    "#path = '/data/home/zhaocj/spn_forcast/df数据整理/../11mer_output/RBIND_11mer'\n",
    "#path = '../9mer_output/RBIND_9mer'\n",
    "\n",
    "# test.txt 是X92到X99这几株菌的合并\n",
    "#path = '../11mer_output/test.txt'\n",
    "\n",
    "# test2 是每株菌的head\n",
    "#path = '../11mer_output/test2.txt'\n",
    "\n",
    "# test3 只是100这株菌\n",
    "#path = '../11mer_output/test3.txt'\n",
    "\n",
    "# test4 是每株菌的head, 整理后的数据\n",
    "#path = '../11mer_output/test4.txt'\n",
    "\n",
    "# test5 是整理后的数据，是准确的\n",
    "#path = '../11mer_output/test5.sh'\n",
    "\n",
    "drug = 'PEN_NM'\n",
    "drug = 'PEN_MIC'\n",
    "\n",
    "try:\n",
    "    df = pd.read_table(path, header=None, names=['SEQ', 'COUNT', 'ID'])\n",
    "    id_number = pd.read_table('/data/home/zhaocj/spn_forcast/df数据整理/ID.txt')\n",
    "    ris = pd.read_table('/data/home/zhaocj/spn_forcast/df数据整理/ris.txt')\n",
    "    mic = pd.read_table('/data/home/zhaocj/spn_forcast/df数据整理/mic.txt')\n",
    "    sero = pd.read_table('/data/home/zhaocj/seroba/summary.tsv', header=None, names=['ID', 'SEROTYPE', 'COMMENT'])\n",
    "    sero2 = pd.read_table('sero2.txt')\n",
    "    sero2['COMMENT'] = 'NaN'\n",
    "    sero = pd.concat([sero, sero2])\n",
    "except:\n",
    "    print('数据导入失败！/(ㄒoㄒ)/~~')\n",
    "else:\n",
    "    print('数据导入成功😄！')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cec3b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运气真好，做对了😄！\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = df.pivot_table(index=['ID'], columns='SEQ', values='COUNT', fill_value=0).reset_index()\n",
    "    \n",
    "    # 把 df 的ID转换为字符型\n",
    "    for i in range(df.shape[0]):\n",
    "        df.iloc[i, 0] = str(df.iloc[i, 0])\n",
    "\n",
    "    # 选取id_number数据表里有的菌\n",
    "    df = df.set_index('ID')\n",
    "    df = df.loc[list(id_number['ID'])].reset_index()\n",
    "    \n",
    "    # 选取id_number数据表里有的血清型\n",
    "    sero = sero.set_index('ID')\n",
    "    sero = sero.loc[list(id_number['ID'])].reset_index()\n",
    "    \n",
    "    \n",
    "    # 如果drug里面有MIC则合并MIC的表\n",
    "    if 'MIC' in drug:\n",
    "        mic = mic[['ID', drug]]\n",
    "        for i in range(mic.shape[0]):\n",
    "            mic.iloc[i, 1] = str(mic.iloc[i, 1])\n",
    "        \n",
    "        # 如果用血清型就用这个，然后把血清型用dummy来计算\n",
    "        #df = pd.merge(df, sero.iloc[:,:-1], how = 'left', on=['ID'])\n",
    "        \n",
    "        df = pd.merge(df, mic, how = 'left', on=['ID'])\n",
    "    else:\n",
    "        ris = ris[['ID', drug]]\n",
    "        \n",
    "        # 如果用血清型就用这个，然后把血清型用dummy来计算\n",
    "        #df = pd.merge(df, sero.iloc[:,:-1], how = 'left', on=['ID'])\n",
    "        \n",
    "        df = pd.merge(df, ris, how = 'left', on=[\"ID\"])\n",
    "    ID = df.iloc[:,0]\n",
    "    df = df.iloc[:,1:]\n",
    "    \n",
    "    \n",
    "    #print(df.head())\n",
    "except:\n",
    "    print('出错了，哪里错了，不知道。')\n",
    "else:\n",
    "    print('运气真好，做对了😄！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "567b4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies(df['PEN_MIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acde3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 血清型作为dammy数据\n",
    "\n",
    "df_dummies = pd.get_dummies(df['SEROTYPE'], drop_first=True)\n",
    "df = pd.concat([df.iloc[:,:-2], df_dummies, df.iloc[:,-1]],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行正态转换后的结果\n",
    "# 正态转换后和没有正态转换的结果是一样的。\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# 正态转换\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test_scaled)\n",
    "\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "\n",
    "print(\"accuracy: %f\" % (accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aeb7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f8566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242f961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc34abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy: 0.559055\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test)\n",
    "\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "\n",
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151757b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ID.loc[X_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵\n",
    "print('混淆矩阵')\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出数据\n",
    "\n",
    "list_dict = {\n",
    "    '菌株号': list(np.array(ID.loc[X_test.index])),\n",
    "    '预测结果': list(preds),\n",
    "    '实际结果': list(np.array(y_test))\n",
    "}\n",
    "\n",
    "pd.DataFrame(list_dict).to_csv(path.split('/')[-2].split('_')[0] + '_' + drug +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix from X and y: churn_dmatrix\n",
    "dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"binary:logistic\", \"max_depth\":3}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=dmatrix, params=params, \n",
    "                    nfold=3, num_boost_round=5, \n",
    "                    metrics=\"error\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46c436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

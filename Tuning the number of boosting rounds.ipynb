{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ddf5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®å¯¼å…¥æˆåŠŸğŸ˜„ï¼\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.metrics         import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = '/data/home/zhaocj/spn_forcast/dfæ•°æ®æ•´ç†/../7mer_output/RBIND_7mer'\n",
    "#path = '/data/home/zhaocj/spn_forcast/dfæ•°æ®æ•´ç†/../11mer_output/RBIND_11mer'\n",
    "#path = '../9mer_output/RBIND_9mer'\n",
    "\n",
    "# test.txt æ˜¯X92åˆ°X99è¿™å‡ æ ªèŒçš„åˆå¹¶\n",
    "#path = '../11mer_output/test.txt'\n",
    "\n",
    "# test2 æ˜¯æ¯æ ªèŒçš„head\n",
    "#path = '../11mer_output/test2.txt'\n",
    "\n",
    "# test3 åªæ˜¯100è¿™æ ªèŒ\n",
    "#path = '../11mer_output/test3.txt'\n",
    "\n",
    "# test4 æ˜¯æ¯æ ªèŒçš„head, æ•´ç†åçš„æ•°æ®\n",
    "#path = '../11mer_output/test4.txt'\n",
    "\n",
    "# test5 æ˜¯æ•´ç†åçš„æ•°æ®ï¼Œæ˜¯å‡†ç¡®çš„\n",
    "#path = '../11mer_output/test5.sh'\n",
    "\n",
    "drug = 'PEN_NM'\n",
    "drug = 'PEN_MIC'\n",
    "\n",
    "try:\n",
    "    df = pd.read_table(path, header=None, names=['SEQ', 'COUNT', 'ID'])\n",
    "    id_number = pd.read_table('/data/home/zhaocj/spn_forcast/dfæ•°æ®æ•´ç†/ID.txt')\n",
    "    ris = pd.read_table('/data/home/zhaocj/spn_forcast/dfæ•°æ®æ•´ç†/ris.txt')\n",
    "    mic = pd.read_table('/data/home/zhaocj/spn_forcast/dfæ•°æ®æ•´ç†/mic.txt')\n",
    "except:\n",
    "    print('æ•°æ®å¯¼å…¥å¤±è´¥ï¼/(ã„’oã„’)/~~')\n",
    "else:\n",
    "    print('æ•°æ®å¯¼å…¥æˆåŠŸğŸ˜„ï¼')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adfaa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿æ°”çœŸå¥½ï¼Œåšå¯¹äº†ğŸ˜„ï¼\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = df.pivot_table(index=['ID'], columns='SEQ', values='COUNT', fill_value=0).reset_index()\n",
    "    \n",
    "    # æŠŠ df çš„IDè½¬æ¢ä¸ºå­—ç¬¦å‹\n",
    "    for i in range(df.shape[0]):\n",
    "        df.iloc[i, 0] = str(df.iloc[i, 0])\n",
    "\n",
    "    # é€‰å–id_numberæ•°æ®è¡¨é‡Œæœ‰çš„èŒ\n",
    "    df = df.set_index('ID')\n",
    "    df = df.loc[list(id_number['ID'])].reset_index()\n",
    "    \n",
    "    \n",
    "    # å¦‚æœdrugé‡Œé¢æœ‰MICåˆ™åˆå¹¶MICçš„è¡¨\n",
    "    if 'MIC' in drug:\n",
    "        mic = mic[['ID', drug]]\n",
    "        for i in range(mic.shape[0]):\n",
    "            mic.iloc[i, 1] = str(mic.iloc[i, 1])\n",
    "        df = pd.merge(df, mic, how = 'left', on=['ID'])\n",
    "    else:\n",
    "        ris = ris[['ID', drug]]\n",
    "        df = pd.merge(df, ris, how = 'left', on=[\"ID\"])\n",
    "    ID = df.iloc[:,0]\n",
    "    df = df.iloc[:,1:]\n",
    "    \n",
    "    #print(df.head())\n",
    "except:\n",
    "    print('å‡ºé”™äº†ï¼Œå“ªé‡Œé”™äº†ï¼Œä¸çŸ¥é“ã€‚')\n",
    "else:\n",
    "    print('è¿æ°”çœŸå¥½ï¼Œåšå¯¹äº†ğŸ˜„ï¼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecfa827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for the features and the target: X, y\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# Create the DMatrix: housing_dmatrix\n",
    "kmer_dmatrix = xgb.DMatrix(data=X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cd9f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter dictionary for each tree: params \n",
    "params = {\"objective\":\"binary:logistic\", \"max_depth\":3}\n",
    "\n",
    "# Create list of number of boosting rounds\n",
    "num_rounds = [5, 10, 15]\n",
    "\n",
    "# Empty list to store final round rmse per XGBoost model\n",
    "final_rmse_per_round = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c62966",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[14:30:27] ../src/objective/regression_obj.cu:120: label must be in [0,1] for logistic regression\nStack trace:\n  [bt] (0) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x455ac9) [0x2b39518e7ac9]\n  [bt] (1) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x46a0b0) [0x2b39518fc0b0]\n  [bt] (2) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x1b4990) [0x2b3951646990]\n  [bt] (3) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x68) [0x2b395152b4f8]\n  [bt] (4) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/../../libffi.so.7(+0x69dd) [0x2b38a5d189dd]\n  [bt] (5) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/../../libffi.so.7(+0x6067) [0x2b38a5d18067]\n  [bt] (6) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x13a) [0x2b38a5d061da]\n  [bt] (7) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x14ce0) [0x2b38a5d06ce0]\n  [bt] (8) /data/build/miniconda3/envs/cenote-taker2_env/bin/python(_PyObject_FastCallDict+0x17c) [0x564c7f7e328c]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-86be2dc1df7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcurr_num_rounds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Perform cross-validation: cv_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkmer_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_num_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Append final round RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mshould_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, obj)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;34m'''Iterate through folds for update'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \"\"\"\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [14:30:27] ../src/objective/regression_obj.cu:120: label must be in [0,1] for logistic regression\nStack trace:\n  [bt] (0) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x455ac9) [0x2b39518e7ac9]\n  [bt] (1) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x46a0b0) [0x2b39518fc0b0]\n  [bt] (2) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x1b4990) [0x2b3951646990]\n  [bt] (3) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x68) [0x2b395152b4f8]\n  [bt] (4) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/../../libffi.so.7(+0x69dd) [0x2b38a5d189dd]\n  [bt] (5) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/../../libffi.so.7(+0x6067) [0x2b38a5d18067]\n  [bt] (6) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x13a) [0x2b38a5d061da]\n  [bt] (7) /data/build/miniconda3/envs/cenote-taker2_env/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x14ce0) [0x2b38a5d06ce0]\n  [bt] (8) /data/build/miniconda3/envs/cenote-taker2_env/bin/python(_PyObject_FastCallDict+0x17c) [0x564c7f7e328c]\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate over num_rounds and build one model per num_boost_round parameter\n",
    "for curr_num_rounds in num_rounds:\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=kmer_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append final round RMSE\n",
    "    #final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "    print(cv_results)\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "#num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n",
    "#print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for the features and the target: X, y\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# æ­£æ€è½¬æ¢\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test_scaled)\n",
    "\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "\n",
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b8fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f40761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring accuracy\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"binary:logistic\", \"max_depth\":3}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=kmer_dmatrix, params=params, \n",
    "                    nfold=3, num_boost_round=5, \n",
    "                    metrics=\"error\", as_pandas=True, seed=123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
